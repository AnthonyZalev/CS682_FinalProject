{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.optim as optimizer\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "1. Random Cropping with size ratio between .08 and 1.0 with resizing. RandomResizedCrop(32, scale=(0.08, 0.1)) in PyTorch.\n",
    "2. Random horizontal flip with probability 0.5.\n",
    "3. Color jittering of brightness, contrast, saturation and hue, with probability 0.8.\n",
    "ColorJitter(0.4, 0.4, 0.2, 0.1) in PyTorch.\n",
    "4. Grayscale with probability 0.2\n",
    "5. Gaussian blur with probability 0.5 and kernel size 23. (Do we keep the sample kernel size for cifar-10?)\n",
    "6. Solarization with probability 0.1.\n",
    "7. Color normalization with mean (0.485, 0.456, 0.406) and standard deviation (0.229, 0.224,\n",
    "0.225).\n",
    "\n",
    "https://pytorch.org/vision/main/transforms.html\n",
    "\n",
    "GAUSSIAN_BLUR:\n",
    "https://pytorch.org/vision/main/generated/torchvision.transforms.GaussianBlur.html#torchvision.transforms.GaussianBlur\n",
    "    Inputs: \n",
    "    - kernel_size (int or sequence) – Size of the Gaussian kernel.\n",
    "    - sigma (float or tuple of python:float (min, max)) – Standard deviation to be used for creating kernel to perform blurring.\n",
    "    If float, sigma is fixed. If it is tuple of float (min, max), sigma is chosen uniformly at random to lie in the given range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=23\n",
    "sigma=(0.1, 2.0)\n",
    "solarize_threshold = .5\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(32, 32), antialias=True),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.2, 0.1),\n",
    "    transforms.RandomGrayscale(.2), # [BETA] Randomly convert image or videos to grayscale with a probability of p (default 0.1).\n",
    "    transforms.GaussianBlur(kernel_size , sigma), # [BETA] Blurs image with randomly chosen Gaussian blur.\n",
    "    transforms.RandomSolarize(solarize_threshold, p = .1),\n",
    "    #transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VicReg Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 25 # invar loss weight\n",
    "mu = 25 # var loss weight\n",
    "nu = 1 # covar loss weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(z, z_prime):\n",
    "    \"\"\"Calculate the loss function. \n",
    "    \n",
    "    The following is heavily based on the psuedo code provided on page 13 of https://arxiv.org/pdf/2105.04906.pdf\n",
    "    \n",
    "    Need to calculate 3 things: \n",
    "    \n",
    "    1. Variance\n",
    "    \n",
    "    2. Invariance\n",
    "    \n",
    "    3. Covariance\n",
    "    \n",
    "    Args:\n",
    "        z (_type_): batch of images transformed, encodeded, projected\n",
    "        z_prime (_type_): batch of images transformed, encodeded, projected\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Variance Loss\n",
    "    var_epsilon = 1e-4\n",
    "    std_z = torch.sqrt(z.var(dim=0) + var_epsilon)\n",
    "    std_z_prime = torch.sqrt(z_prime.var(dim=0) + var_epsilon)\n",
    "    std_loss = torch.mean(F.relu(1 - std_z)) + torch.mean(F.relu(1 - std_z_prime))\n",
    "    \n",
    "    \n",
    "    # 2. Invariance Loss (Just MSE Loss)\n",
    "    invar_loss = F.mse_loss(z, z_prime)\n",
    "    \n",
    "    # 3. Covariance Loss\n",
    "    \n",
    "    N , D = z.shape\n",
    "    z = z - z.mean(dim=0)\n",
    "    z_prime = z_prime - z_prime.mean(dim=0)\n",
    "    cov_z = (z.T @ z) / (N - 1)\n",
    "    cov_z_prime = (z_prime.T @ z_prime) / (N - 1)\n",
    "    \n",
    "    cov_z = cov_z.pow(2)\n",
    "    cov_z_prime = cov_z_prime.pow(2)\n",
    "    \n",
    "    loss_c_a = (cov_z.sum() - cov_z.diagonal().sum()) / D\n",
    "    loss_c_b = (cov_z_prime.sum() - cov_z_prime.diagonal().sum()) / D\n",
    "    \n",
    "    loss_cov = loss_c_a + loss_c_b\n",
    "    \n",
    "    loss = lamb * invar_loss + mu * std_loss + nu * loss_cov\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SameTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "40000\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 256\n",
    "default_transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download = True, transform = default_transform)\n",
    "\n",
    "split_ratio = 0.8\n",
    "total_size = len(trainset)\n",
    "train_size = int(split_ratio * total_size)\n",
    "valid_size = total_size - train_size\n",
    "print(train_size)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(trainset, [train_size, valid_size])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform = default_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "- Standard ResNet - 50 Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, output_units=512):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Load pre-trained ResNet-50 model from torchvision\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Remove the fully connected layers at the end\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "        # Add global average pooling layer\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Output projection layer\n",
    "        self.projection_layer = nn.Linear(2048, output_units)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through ResNet-50 backbone\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Projection layer\n",
    "        x = self.projection_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the Encoder with 512 output units\n",
    "encoder = Encoder(output_units=512)\n",
    "\n",
    "# Test the encoder with a random input\n",
    "random_input = torch.randn((1, 3, 224, 224))  # Assuming input image size is 224x224\n",
    "output = encoder(random_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expander(nn.Module):\n",
    "    def __init__(self, input_size, output_size=8192):\n",
    "        \"\"\"\n",
    "        \n",
    "        expander hφ:\n",
    "        Composed of two fully-connected layers with batch normalization and ReLU,\n",
    "        and a third linear layer. The sizes of all 3 layers were set to 8192\n",
    "\n",
    "        Args:\n",
    "            input_size (int): cifar vector size \n",
    "            output_size (int): output vector size, also size of intermediate linear layers.\n",
    "        \"\"\"\n",
    "        super(Expander, self).__init__()\n",
    "\n",
    "          # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # First fully-connected layer\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.bn1 = nn.BatchNorm1d(output_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Second fully-connected layer\n",
    "        self.fc2 = nn.Linear(output_size, output_size)\n",
    "        self.bn2 = nn.BatchNorm1d(output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third linear layer\n",
    "        self.fc3 = nn.Linear(output_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if x.size(0) > 1:\n",
    "            x = self.bn1(x)\n",
    "\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if x.size(0) > 1:\n",
    "            x = self.bn2(x)\n",
    "\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded output shape: torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "expander = Expander(input_size=512, output_size=2048)\n",
    "expanded_output = expander(output)\n",
    "print(\"Expanded output shape:\", expanded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VICReg(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_size, expander_size):\n",
    "       \n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoder_size)\n",
    "        self.expander = Expander(encoder_size, expander_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.expander(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_epochs = 50\n",
    "\n",
    "# Hyper parameters\n",
    "learning_rate_decay = 10e-6\n",
    "batch_size = 256\n",
    "encoder_size = 256\n",
    "expander_size = 512\n",
    "base_lr = .01\n",
    "\n",
    "#encoder = ResNet50_Weights.DEFAULT.transforms()\n",
    "#expander = Expander(encoder_size, expander_size)\n",
    "\n",
    "lr = (batch_size / 256) * base_lr\n",
    "\n",
    "model = VICReg(encoder_size, expander_size)\n",
    "model.to(device)\n",
    "params = model.parameters()\n",
    "optimiz = optimizer.SGD(params, lr = lr, weight_decay= learning_rate_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.6075, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/157 [00:18<19:48,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(39.2890, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/157 [00:18<11:23,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.6002, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/157 [00:19<07:27,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.3940, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/157 [00:20<05:16,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.8999, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/157 [00:20<03:57,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.6960, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/157 [00:21<03:08,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.7402, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/157 [00:21<02:35,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.2629, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/157 [00:22<02:13,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.1990, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 10/157 [00:23<01:58,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.7832, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/157 [00:23<01:48,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.2666, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12/157 [00:24<01:41,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.8624, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/157 [00:24<01:36,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.0759, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/157 [00:25<01:31,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.5139, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 15/157 [00:26<01:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.3466, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 16/157 [00:26<01:26,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.9120, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 17/157 [00:27<01:25,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.8515, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 18/157 [00:27<01:24,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.2447, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/157 [00:28<01:23,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.0279, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/157 [00:29<01:22,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.5178, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/157 [00:29<01:21,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.0042, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 22/157 [00:30<01:20,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.1645, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 23/157 [00:30<01:20,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.3390, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 24/157 [00:31<01:19,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.6897, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 25/157 [00:32<01:19,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.6175, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 26/157 [00:32<01:18,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.5574, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/157 [00:33<01:17,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.3419, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 28/157 [00:33<01:17,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.4368, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 29/157 [00:34<01:16,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.3829, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30/157 [00:35<01:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.3691, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 31/157 [00:35<01:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.5535, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 32/157 [00:36<01:14,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(35.3534, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 33/157 [00:36<01:14,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(35.6452, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 34/157 [00:37<01:13,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.7222, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35/157 [00:38<01:13,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.6905, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 36/157 [00:38<01:12,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.0516, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 37/157 [00:39<01:11,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.7217, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 38/157 [00:39<01:10,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.2134, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 39/157 [00:40<01:11,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(36.4855, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 40/157 [00:41<01:11,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(35.8487, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 41/157 [00:41<01:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(35.4543, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 42/157 [00:42<01:09,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(38.4773, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/157 [00:42<01:09,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(35.7569, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 44/157 [00:43<01:07,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "encoder done\n",
      "tensor(37.5954, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train_loop(model, optimizer, trainloader, criterion, device):\n",
    "    tk0 = tqdm(trainloader)\n",
    "    train_loss = []\n",
    "\n",
    "    for batch, _ in tk0:\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        x = transform(batch)\n",
    "        x1 = transform(batch)\n",
    "    \n",
    "        fx = model(x)\n",
    "        fx1 = model(x1)\n",
    "        loss = criterion(fx, fx1)\n",
    "        #print(loss)\n",
    "        train_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    train_loss = train_loop(model, optimiz, trainloader, calculate_loss, device)\n",
    "    print(np.mean(train_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
